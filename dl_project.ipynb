{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neneeeee/entrance-exam-2022/blob/main/dl_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-23T09:59:28.390773Z",
          "iopub.status.busy": "2022-08-23T09:59:28.390254Z",
          "iopub.status.idle": "2022-08-23T09:59:28.423880Z",
          "shell.execute_reply": "2022-08-23T09:59:28.422598Z",
          "shell.execute_reply.started": "2022-08-23T09:59:28.390737Z"
        },
        "trusted": true,
        "id": "rG3P1Y0tLB-Y"
      },
      "outputs": [],
      "source": [
        "import os, gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from hyperopt import hp, fmin, tpe, Trials\n",
        "from hyperopt.pyll.base import scope\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import GroupKFold\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from joblib import dump, load\n",
        "import datatable as dtable\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.layers as layers\n",
        "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "\n",
        "TEST = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-23T09:59:28.429377Z",
          "iopub.status.busy": "2022-08-23T09:59:28.428923Z",
          "iopub.status.idle": "2022-08-23T09:59:28.435076Z",
          "shell.execute_reply": "2022-08-23T09:59:28.434269Z",
          "shell.execute_reply.started": "2022-08-23T09:59:28.429334Z"
        },
        "trusted": true,
        "id": "UKpidxpcLB-b"
      },
      "outputs": [],
      "source": [
        "def weighted_average(a):\n",
        "    w = []\n",
        "    n = len(a)\n",
        "    for j in range(1, n + 1):\n",
        "        j = 2 if j == 1 else j\n",
        "        w.append(1 / (2**(n + 1 - j)))\n",
        "    return np.average(a, weights = w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-23T09:59:28.462459Z",
          "iopub.status.busy": "2022-08-23T09:59:28.461928Z",
          "iopub.status.idle": "2022-08-23T09:59:28.471080Z",
          "shell.execute_reply": "2022-08-23T09:59:28.470268Z",
          "shell.execute_reply.started": "2022-08-23T09:59:28.462424Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "4k0jUYUSLB-c",
        "outputId": "67c0cc6d-0814-4f05-d06d-8f542ce98ddd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# time series split\\ntss = TimeSeriesSplit(n_splits = 5, gap =5, max_train_size = 60)\\nfor train_index, test_index in tss.split(data):\\n     print(\"TRAIN:\", train_index, \"TEST:\", test_index)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "'''# time series split\n",
        "tss = TimeSeriesSplit(n_splits = 5, gap =5, max_train_size = 60)\n",
        "for train_index, test_index in tss.split(data):\n",
        "     print(\"TRAIN:\", train_index, \"TEST:\", test_index)'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PkoG68FLB-d"
      },
      "source": [
        "preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-23T09:59:28.559241Z",
          "iopub.status.busy": "2022-08-23T09:59:28.558036Z",
          "iopub.status.idle": "2022-08-23T09:59:28.574734Z",
          "shell.execute_reply": "2022-08-23T09:59:28.573784Z",
          "shell.execute_reply.started": "2022-08-23T09:59:28.559132Z"
        },
        "trusted": true,
        "id": "1ltAJp-3LB-f"
      },
      "outputs": [],
      "source": [
        "#grouptimeseries\n",
        "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
        "from sklearn.utils.validation import _deprecate_positional_args\n",
        "\n",
        "class GroupTimeSeriesSplit(_BaseKFold):\n",
        "    @_deprecate_positional_args\n",
        "    def __init__(self, n_splits=5, *, max_train_size=None):\n",
        "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
        "        self.max_train_size = max_train_size\n",
        "    def split(self, X, y=None, groups=None):\n",
        "        if groups is None:\n",
        "            raise ValueError(\n",
        "                \"The 'groups' parameter should not be None\")\n",
        "        X, y, groups = indexable(X, y, groups)\n",
        "        n_samples = _num_samples(X)\n",
        "        n_splits = self.n_splits\n",
        "        n_folds = n_splits + 1\n",
        "        group_dict = {}\n",
        "        u, ind = np.unique(groups, return_index=True)\n",
        "        unique_groups = u[np.argsort(ind)]\n",
        "        n_samples = _num_samples(X)\n",
        "        n_groups = _num_samples(unique_groups)\n",
        "        \n",
        "        for idx in np.arange(n_samples):\n",
        "            if (groups[idx] in group_dict):\n",
        "                group_dict[groups[idx]].append(idx)\n",
        "            else:\n",
        "                group_dict[groups[idx]] = [idx]\n",
        "        if n_folds > n_groups:\n",
        "            raise ValueError(\n",
        "                (\"Cannot have number of folds={0} greater than\"\n",
        "                 \" the number of groups={1}\").format(n_folds, n_groups))\n",
        "        group_test_size = n_groups // n_folds\n",
        "        group_test_starts = range(n_groups - n_splits * group_test_size, n_groups, group_test_size)\n",
        "        \n",
        "        for group_test_start in group_test_starts:\n",
        "            train_array = []\n",
        "            test_array = []\n",
        "            for train_group_idx in unique_groups[:group_test_start]:\n",
        "                train_array_tmp = group_dict[train_group_idx]\n",
        "                train_array = np.sort(np.unique(\n",
        "                                      np.concatenate((train_array, train_array_tmp)),axis=None), axis=None)\n",
        "            #train_end = train_array.size\n",
        "            if self.max_train_size and self.max_train_size < train_end:\n",
        "                train_array = train_array[train_end - self.max_train_size:train_end]\n",
        "            for test_group_idx in unique_groups[group_test_start:\n",
        "                                                group_test_start +\n",
        "                                                group_test_size]:\n",
        "                test_array_tmp = group_dict[test_group_idx]\n",
        "                test_array = np.sort(np.unique(\n",
        "                                              np.concatenate((test_array, test_array_tmp)),axis=None), axis=None)\n",
        "            yield [int(i) for i in train_array], [int(i) for i in test_array]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-23T09:59:28.618499Z",
          "iopub.status.busy": "2022-08-23T09:59:28.617005Z",
          "iopub.status.idle": "2022-08-23T09:59:28.636184Z",
          "shell.execute_reply": "2022-08-23T09:59:28.635267Z",
          "shell.execute_reply.started": "2022-08-23T09:59:28.618447Z"
        },
        "trusted": true,
        "id": "4m5rmojcLB-h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
        "from sklearn.utils.validation import _deprecate_positional_args\n",
        "\n",
        "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
        "    \"\"\"\n",
        "    n_splits : int, default=5\n",
        "        Number of splits. Must be at least 2.\n",
        "    max_train_group_size : int, default=Inf\n",
        "        Maximum group size for a single training set.\n",
        "    group_gap : int, default=None\n",
        "        Gap between train and test\n",
        "    max_test_group_size : int, default=Inf\n",
        "    \"\"\"\n",
        "    @_deprecate_positional_args\n",
        "    def __init__(self,\n",
        "                 n_splits=5,\n",
        "                 *,\n",
        "                 max_train_group_size=np.inf,\n",
        "                 max_test_group_size=np.inf,\n",
        "                 group_gap=None,\n",
        "                 verbose=False\n",
        "                 ):\n",
        "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
        "        self.max_train_group_size = max_train_group_size\n",
        "        self.group_gap = group_gap\n",
        "        self.max_test_group_size = max_test_group_size\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def split(self, X, y=None, groups=None):\n",
        "        \"\"\"\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training data, where n_samples is the number of samples\n",
        "            and n_features is the number of features.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Always ignored, exists for compatibility.\n",
        "        groups : array-like of shape (n_samples,)\n",
        "            Group labels for the samples used while splitting the dataset into\n",
        "            train/test set.\n",
        "        Yields\n",
        "        ------\n",
        "        train : ndarray\n",
        "            The training set indices for that split.\n",
        "        test : ndarray\n",
        "            The testing set indices for that split.\n",
        "        \"\"\"\n",
        "        if groups is None:\n",
        "            raise ValueError(\n",
        "                \"The 'groups' parameter should not be None\")\n",
        "        X, y, groups = indexable(X, y, groups)\n",
        "        n_samples = _num_samples(X)\n",
        "        n_splits = self.n_splits\n",
        "        group_gap = self.group_gap\n",
        "        max_test_group_size = self.max_test_group_size\n",
        "        max_train_group_size = self.max_train_group_size\n",
        "        n_folds = n_splits + 1\n",
        "        group_dict = {}\n",
        "        u, ind = np.unique(groups, return_index=True)\n",
        "        unique_groups = u[np.argsort(ind)]\n",
        "        n_samples = _num_samples(X)\n",
        "        n_groups = _num_samples(unique_groups)\n",
        "        for idx in np.arange(n_samples):\n",
        "            if (groups[idx] in group_dict):\n",
        "                group_dict[groups[idx]].append(idx)\n",
        "            else:\n",
        "                group_dict[groups[idx]] = [idx]\n",
        "        if n_folds > n_groups:\n",
        "            raise ValueError(\n",
        "                (\"Cannot have number of folds={0} greater than\" \" the number of groups={1}\").format(n_folds,n_groups))\n",
        "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
        "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
        "                                  n_groups, group_test_size)\n",
        "        for group_test_start in group_test_starts:\n",
        "            train_array = []\n",
        "            test_array = []\n",
        "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
        "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
        "                train_array_tmp = group_dict[train_group_idx]\n",
        "                train_array = np.sort(np.unique(np.concatenate((train_array,train_array_tmp)),axis=None), axis=None)\n",
        "            train_end = train_array.size\n",
        " \n",
        "            for test_group_idx in unique_groups[group_test_start:\n",
        "                                                group_test_start +\n",
        "                                                group_test_size]:\n",
        "                test_array_tmp = group_dict[test_group_idx]\n",
        "                test_array = np.sort(np.unique(np.concatenate((test_array, test_array_tmp)), axis=None), axis=None)\n",
        "\n",
        "            test_array  = test_array[group_gap:]\n",
        "            \n",
        "            if self.verbose > 0:\n",
        "                    pass\n",
        "                    \n",
        "            yield [int(i) for i in train_array], [int(i) for i in test_array]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbxZl1fELB-i",
        "outputId": "a3caabc6-1416-4fe6-a152-eae318823232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datatable in /usr/local/lib/python3.7/dist-packages (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "pip install datatable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-23T09:59:28.649625Z",
          "iopub.status.busy": "2022-08-23T09:59:28.648875Z",
          "iopub.status.idle": "2022-08-23T09:59:28.736491Z",
          "shell.execute_reply": "2022-08-23T09:59:28.734536Z",
          "shell.execute_reply.started": "2022-08-23T09:59:28.649581Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSXPlfN9LB-j",
        "outputId": "edf9f7bf-5780-4573-d085-492b70a01389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading...\n",
            "Filling...\n"
          ]
        }
      ],
      "source": [
        "import datatable as dtable\n",
        "if TEST:\n",
        "    train = pd.read_csv(r'/content/train.csv', nrows = 100)\n",
        "    features = [c for c in train.columns if 'feature' in c]\n",
        "else:\n",
        "    print('Loading...')\n",
        "    train = dtable.fread('/content/train.csv', fill=True).to_pandas()\n",
        "    features = [c for c in train.columns if 'feature' in c]\n",
        "\n",
        "    print('Filling...')\n",
        "    train = train.query('date > 0').reset_index(drop = True) \n",
        "    train = train.query('weight > 0').reset_index(drop = True)\n",
        "    train[features] = train[features].fillna(method = 'ffill').fillna(0)\n",
        "    train['action'] = ((train['resp_1'] > 0) & (train['resp_2'] > 0) & (train['resp_3'] > 0) & (train['resp_4'] > 0) & (train['resp'] > 0)).astype('int')\n",
        "\n",
        "    resp_cols = ['resp', 'resp_1', 'resp_2', 'resp_3', 'resp_4']\n",
        "\n",
        "    X = train[features].values\n",
        "    y = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T\n",
        "    date = train['date'].values\n",
        "    #weight = train['weight'].values\n",
        "    resp = train['resp'].values\n",
        "    sw = np.mean(np.abs(train[resp_cols].values), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-23T09:59:28.737322Z",
          "iopub.status.idle": "2022-08-23T09:59:28.737803Z",
          "shell.execute_reply": "2022-08-23T09:59:28.737589Z",
          "shell.execute_reply.started": "2022-08-23T09:59:28.737555Z"
        },
        "trusted": true,
        "id": "315-AzlcLB-j"
      },
      "outputs": [],
      "source": [
        "n_splits = 5\n",
        "group_gap = 31"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5Jv46QDLB-k"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-23T09:59:28.739625Z",
          "iopub.status.idle": "2022-08-23T09:59:28.740124Z",
          "shell.execute_reply": "2022-08-23T09:59:28.739882Z",
          "shell.execute_reply.started": "2022-08-23T09:59:28.739856Z"
        },
        "trusted": true,
        "id": "PveOXijALB-k"
      },
      "outputs": [],
      "source": [
        "def create_ae_mlp(num_columns, num_labels, hidden_units, dropout_rates, ls = 1e-2, lr = 1e-3):\n",
        "    \n",
        "    inp = tf.keras.layers.Input(shape = (num_columns, ))\n",
        "    x0 = tf.keras.layers.BatchNormalization()(inp)\n",
        "    \n",
        "    encoder = tf.keras.layers.GaussianNoise(dropout_rates[0])(x0)\n",
        "    encoder = tf.keras.layers.Dense(hidden_units[0])(encoder)\n",
        "    encoder = tf.keras.layers.BatchNormalization()(encoder)\n",
        "    encoder = tf.keras.layers.Activation('relu')(encoder)\n",
        "    \n",
        "    decoder = tf.keras.layers.Dropout(dropout_rates[1])(encoder)\n",
        "    decoder = tf.keras.layers.Dense(num_columns, name = 'decoder')(decoder)\n",
        "\n",
        "    x_ae = tf.keras.layers.Dense(hidden_units[1])(decoder)\n",
        "    x_ae = tf.keras.layers.BatchNormalization()(x_ae)\n",
        "    x_ae = tf.keras.layers.Activation('relu')(x_ae)\n",
        "    x_ae = tf.keras.layers.Dropout(dropout_rates[2])(x_ae)\n",
        "\n",
        "    out_ae = tf.keras.layers.Dense(num_labels, activation = 'sigmoid', name = 'ae_action')(x_ae)\n",
        "    \n",
        "    x = tf.keras.layers.Concatenate()([x0, encoder])\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rates[3])(x)\n",
        "    \n",
        "    for i in range(2, len(hidden_units)):\n",
        "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "        x = tf.keras.layers.Dropout(dropout_rates[i + 2])(x)\n",
        "        \n",
        "    out = tf.keras.layers.Dense(num_labels, activation = 'sigmoid', name = 'action')(x)\n",
        "    \n",
        "    model = tf.keras.models.Model(inputs = inp, outputs = [decoder, out_ae, out])\n",
        "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = lr),\n",
        "                  loss = {'decoder': tf.keras.losses.MeanSquaredError(), \n",
        "                          'ae_action': tf.keras.losses.BinaryCrossentropy(label_smoothing = ls),\n",
        "                          'action': tf.keras.losses.BinaryCrossentropy(label_smoothing = ls), \n",
        "                         },\n",
        "                  metrics = {'decoder': tf.keras.metrics.MeanAbsoluteError(name = 'MAE'), \n",
        "                             'ae_action': tf.keras.metrics.AUC(name = 'AUC'), \n",
        "                             'action': tf.keras.metrics.AUC(name = 'AUC'), \n",
        "                            }, \n",
        "                 )\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-23T09:59:28.742324Z",
          "iopub.status.idle": "2022-08-23T09:59:28.742928Z",
          "shell.execute_reply": "2022-08-23T09:59:28.742675Z",
          "shell.execute_reply.started": "2022-08-23T09:59:28.742647Z"
        },
        "trusted": true,
        "id": "4_nb0ZhDLB-l"
      },
      "outputs": [],
      "source": [
        "params = {'num_columns': len(features), \n",
        "          'num_labels': 5, \n",
        "          'hidden_units': [96, 96, 896, 448, 448, 256], \n",
        "          'dropout_rates': [0.03527936123679956, 0.038424974585075086, 0.42409238408801436, 0.10431484318345882, 0.49230389137187497, 0.32024444956111164, 0.2716856145683449, 0.4379233941604448], \n",
        "          'ls': 0, \n",
        "          'lr':1e-3, \n",
        "         }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not TEST:\n",
        "    scores = []\n",
        "    batch_size = 4096\n",
        "    gkf = PurgedGroupTimeSeriesSplit(n_splits = n_splits, group_gap = group_gap)\n",
        "    for fold, (tr, te) in enumerate(gkf.split(train['action'].values, train['action'].values, train['date'].values)):\n",
        "        ckp_path = f'JSModel_{fold}.hdf5'\n",
        "        model = create_ae_mlp(**params)\n",
        "        ckp = ModelCheckpoint(ckp_path, monitor = 'val_action_AUC', verbose = 0, \n",
        "                              save_best_only = True, save_weights_only = True, mode = 'max')\n",
        "        es = EarlyStopping(monitor = 'val_action_AUC', min_delta = 1e-4, patience = 10, mode = 'max', \n",
        "                           baseline = None, restore_best_weights = True, verbose = 0)\n",
        "        history = model.fit(X[tr], [X[tr], y[tr], y[tr]], validation_data = (X[te], [X[te], y[te], y[te]]), \n",
        "                            sample_weight = sw[tr], \n",
        "                            epochs = 20, batch_size = batch_size, callbacks = [ckp, es], verbose = 0)\n",
        "        hist = pd.DataFrame(history.history)\n",
        "        score = hist['val_action_AUC'].average()\n",
        "        #score = hist['val_action_AUC'].max()\n",
        "        print(f'Fold {fold} ROC AUC:\\t', score)\n",
        "        scores.append(score)\n",
        "\n",
        "        #K.clear_session()\n",
        "        #del model\n",
        "        #rubbish = gc.collect()\n",
        "        #if fold == 1:\n",
        "         # print('Weighted Average CV Score:', weighted_average(scores))\n",
        "        #break;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tOCUEqPMAhq",
        "outputId": "f7edece9-7533-4b22-8a9b-ef5e463e9d37"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 ROC AUC:\t 0.5504477620124817\n",
            "Fold 1 ROC AUC:\t 0.5439769625663757\n",
            "Fold 2 ROC AUC:\t 0.4994007349014282\n",
            "Fold 3 ROC AUC:\t 0.5030107498168945\n",
            "Fold 4 ROC AUC:\t 0.5032048225402832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not TEST:\n",
        "    scores = []\n",
        "    batch_size = 4096\n",
        "    gkf = PurgedGroupTimeSeriesSplit(n_splits = n_splits, group_gap = group_gap)\n",
        "    for fold, (tr, te) in enumerate(gkf.split(train['action'].values, train['action'].values, train['date'].values)):\n",
        "        ckp_path = f'JSModel_{fold}.hdf5'\n",
        "        model = create_ae_mlp(**params)\n",
        "        ckp = ModelCheckpoint(ckp_path, monitor = 'val_action_AUC', verbose = 0, \n",
        "                              save_best_only = True, save_weights_only = True, mode = 'max')\n",
        "        es = EarlyStopping(monitor = 'val_action_AUC', min_delta = 1e-4, patience = 10, mode = 'max', \n",
        "                           baseline = None, restore_best_weights = True, verbose = 0)\n",
        "        history = model.fit(X[tr], [X[tr], y[tr], y[tr]], validation_data = (X[te], [X[te], y[te], y[te]]), \n",
        "                            sample_weight = sw[tr], \n",
        "                            epochs = 10, batch_size = batch_size, callbacks = [ckp, es], verbose = 0)\n",
        "        hist = pd.DataFrame(history.history)\n",
        "        score = hist['val_action_AUC'].max()\n",
        "        print(f'Fold {fold} ROC AUC:\\t', score)\n",
        "        scores.append(score)\n",
        "\n",
        "        #K.clear_session()\n",
        "        #del model\n",
        "        #rubbish = gc.collect()\n",
        "        #if fold == 1:\n",
        "         # print('Weighted Average CV Score:', weighted_average(scores))\n",
        "        #break;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojYe4YX1Kb0G",
        "outputId": "d4bb9ab3-0a50-4a0a-8596-b3018fd36bd1"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 ROC AUC:\t 0.5168418884277344\n",
            "Fold 1 ROC AUC:\t 0.5158668160438538\n",
            "Fold 2 ROC AUC:\t 0.5029224753379822\n",
            "Fold 3 ROC AUC:\t 0.5018502473831177\n",
            "Fold 4 ROC AUC:\t 0.5027694702148438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edn-S-9XuhFY",
        "outputId": "9d5983a9-4731-4d36-d113-81927dbe0acf"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['loss', 'decoder_loss', 'ae_action_loss', 'action_loss', 'decoder_MAE',\n",
              "       'ae_action_AUC', 'action_AUC', 'val_loss', 'val_decoder_loss',\n",
              "       'val_ae_action_loss', 'val_action_loss', 'val_decoder_MAE',\n",
              "       'val_ae_action_AUC', 'val_action_AUC'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BuFFadHLB-m"
      },
      "source": [
        "loss graph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc = hist['val_action_AUC']\n",
        "val_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVcXmToKyQ1q",
        "outputId": "21285b95-efaa-42ee-8598-95a366a26e77"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0.500487\n",
              "1     0.500263\n",
              "2     0.500224\n",
              "3     0.499328\n",
              "4     0.498854\n",
              "5     0.498585\n",
              "6     0.501506\n",
              "7     0.502275\n",
              "8     0.503205\n",
              "9     0.503136\n",
              "10    0.501971\n",
              "11    0.503116\n",
              "12    0.502552\n",
              "13    0.501847\n",
              "14    0.502246\n",
              "15    0.502835\n",
              "16    0.502803\n",
              "17    0.502732\n",
              "18    0.502021\n",
              "Name: val_action_AUC, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "validation accuracy"
      ],
      "metadata": {
        "id": "d0BIvWXoJYMP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-23T09:59:28.754365Z",
          "iopub.status.busy": "2022-08-23T09:59:28.754039Z",
          "iopub.status.idle": "2022-08-23T09:59:28.775065Z",
          "shell.execute_reply": "2022-08-23T09:59:28.773313Z",
          "shell.execute_reply.started": "2022-08-23T09:59:28.754335Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "QGnZlUT1LB-m",
        "outputId": "4cba58e3-1a2c-4425-e540-3e59d1f9a996"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-149-aa3d7cab6bbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m#plt.plot(epochs, loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (9,) and (19,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import cm\n",
        "#color = iter(cm.rainbow(np.linspace(0, 1, fold)))\n",
        "epochs = range(1, 11)\n",
        "for i in range(fold):\n",
        "  #c = next(color)\n",
        "  train_acc = hist['val_ae_action_AUC']\n",
        "  val_acc = hist['val_acc']\n",
        "  plt.plot(epochs, acc)\n",
        "  #plt.plot(epochs, acc, c = c)\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.ylabel(\"acc\")\n",
        "  plt.legend()\n",
        "plt.show()\n",
        "plt.title(\"validation acc\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMHFa7gwLB-m"
      },
      "source": [
        "acc graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-23T09:59:28.776551Z",
          "iopub.status.idle": "2022-08-23T09:59:28.777045Z",
          "shell.execute_reply": "2022-08-23T09:59:28.776848Z",
          "shell.execute_reply.started": "2022-08-23T09:59:28.776828Z"
        },
        "trusted": true,
        "id": "1MGD3KMQLB-n"
      },
      "outputs": [],
      "source": [
        "for i in range(fold):\n",
        "  #c = next(color)\n",
        "  loss = hist['val_action_loss']\n",
        "  plt.plot(epochs, loss)\n",
        "  #plt.plot(epochs, loss, c = c)\n",
        "  plt.xlabel(\"epochs\")\n",
        "  plt.ylabel(\"loss\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.title(\"validation acc\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGNDP_RiLB-n"
      },
      "source": [
        "predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-23T09:59:28.785501Z",
          "iopub.status.busy": "2022-08-23T09:59:28.784768Z",
          "iopub.status.idle": "2022-08-23T09:59:28.791921Z",
          "shell.execute_reply": "2022-08-23T09:59:28.791072Z",
          "shell.execute_reply.started": "2022-08-23T09:59:28.785463Z"
        },
        "trusted": true,
        "id": "2XXcP5QnLB-n"
      },
      "outputs": [],
      "source": [
        "'''def predict(model, data, threshold):\n",
        "    reconstructtions = model(data)\n",
        "    loss = tf.keras.losses.mae(reconstruction, data)\n",
        "    return tf.math.less(loss, threshold)\n",
        "def print_stats(predictions, labels):\n",
        "    print(\"Accuracy = {}\".format(accuracy_score(labels, predictions)))\n",
        "    print(\"Precision = {}\".format(precision_score(labels, predictions)))\n",
        "    print(\"Recall = {}\".format(recall_score(labels, predictions)))'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-08-23T09:59:28.808634Z",
          "iopub.status.busy": "2022-08-23T09:59:28.808238Z",
          "iopub.status.idle": "2022-08-23T09:59:28.827813Z",
          "shell.execute_reply": "2022-08-23T09:59:28.826047Z",
          "shell.execute_reply.started": "2022-08-23T09:59:28.808602Z"
        },
        "trusted": true,
        "id": "VvUd5H-RLB-n"
      },
      "outputs": [],
      "source": [
        "'''pred = predict(autoencoder, test_data, threshold)\n",
        "print_stat(preds, test_labels)'''"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "0c3c8a6ac696fee7353a0b3d6a5827a15c9d73138c37cbb408c14fa438651459"
      }
    },
    "colab": {
      "name": "dl-project.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}